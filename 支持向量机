给定一个特征空间上的训练数据集$T=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),...,(\vec{x}_N,y_N)\}$ ,其中，$\vec{x}_i = (x_i^{(1)},x_i^{(2)},...,x_i^{(n)}) \in  X = R^n$,$y_i \in Y = {+1,-1},i = 1,2,...,N$。
- 若 $y_i = +1$,则称$\vec{x}_i$为正例；
- 若 $y_i = -1$,则称$\vec{x}_i$为负例。
假设训练集数据集线性可分，希望在特征空间中找到一个分离超平面，它能将所有的正例划分到超平面的一侧、所有的负例划分到超平面的另一侧。由于超平面可以用方程$\vec{w}\times \vec{x} + b = 0)$表示，它由法向量$\vec{w}$和截距项$b$来表示。

当训练集线性可分时，理论上存在无穷多个超平面可以将训练集划分开来。线性可分向量机提出了选择间隔最大化的约束，最终求得的超平面唯一。

假定学习到的超平面为：$\vec{w}^*\times \vec{x} + b^* = 0$
定义分类决策函数为：$f(\vec{x}) = sign(\vec{w}^*\times \vec{x} + b^*)$
该分类决策函数被称为线性可分支持向量机。

通常可以将一个样本离超平面的距离来表示分类预测的可靠性：一个样本离超平面越远，则分类越靠谱。

**给定超平面$\vec{w}\times\vec{x} + b = 0$,样本$\vec{x}_i$到超平面的距离为：$|\vec{w}\times\vec{x}_i+b|$。$\vec{w}\times\vec{x}_i+b$的符号与$y_i$的符号是否一致表示分类是否正确**。

所以用$y\times(\vec{w}\times\vec{x} + b)$来表示分类的正确性以及却星都（符号决定了正确性，范数决定了可信度）。

给定训练数据集$T$,给定超平面$(\vec{w},b)$,定义超平面关于样本点$(\vec{x}_i,y_i)$几何距离为：
$$\hat{\gamma}_i = y_i(\frac{\vec{w}}{||\vec{w}||}\times\vec{x}+\frac{b}{||\vec{w}||})$$
**定义超平面关于训练集T的几何距离为超平面关于T所有样本点$(\vec{x}_i,y_i)$的几何距离的最小值:$\hat{\gamma} = min_{\vec{x}_i\in T}\hat{\gamma}_i$。**

支持向量机的目标是：求解能够正确划分训练数据集，且几何距离最大的分离超平面。
即：
$$max_{\vec{w},b}\gamma$$
$s.t.$
$$y_i\times(\vec{w}\times\vec{x_i} + b)≥1,i = 1,2,...,N$$
等价于
$$min_{\vec{w},b}1/2||\vec{w}||_2^2$$
$s.t.$
$$y_i\times(\vec{w}\times\vec{x_i} + b)≥1,i = 1,2,...,N$$

